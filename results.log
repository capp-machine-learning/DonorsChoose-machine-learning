# Deleted the existing log file.

# LOADING the data...
    >>> SUCCESS!

# Converting the data into preconfigured dtypes...
    >>> SUCCESS!

#########################################################

SUMMARY for the loaded dataset

The total number of rows is 124976

The total number of rows is 25

Descriptive Statistics:

       school_ncesid  ...  students_reached
count   1.157430e+05  ...     124917.000000
mean    2.448448e+11  ...         95.445760
std     1.644728e+11  ...        163.481912
min     1.000050e+10  ...          1.000000
25%     6.344101e+10  ...         23.000000
50%     2.200870e+11  ...         30.000000
75%     3.704880e+11  ...        100.000000
max     6.100010e+11  ...      12143.000000

[8 rows x 5 columns]


#########################################################


# Attempting to SELECT the following features:
    ['school_latitude', 'school_longitude', 'school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'total_price_including_optional_support', 'students_reached', 'eligible_double_your_impact_match', 'date_posted', 'datefullyfunded']...
    >>> SUCCESS!

# Attempting to GENERATE a label called 'fullyfunded_within_60days' based on ['date_posted', 'datefullyfunded']...
    >>> SUCCESS!

# Attempting to SPLIT the data temporally...
# with each test set starting on the following dates:
['2012-07-01', '2013-01-01', '2013-07-01']


#########################################################

# CREATING train/test sets with:
        - TRAIN SET: 2012-01-01 00:00:00 - 2012-05-01 00:00:00,
        - TEST SET: 2012-07-01 00:00:00 - 2012-12-31 00:00:00

# Discretizing 'teacher_prefix'...
    >>> SUCCESS!

# Discretizing 'school_state'...
    >>> SUCCESS!

# Attempting to IMPUTE the missing data...

- For 'school_metro', the most FREQUENT value is selected.
- For 'students_reached', the MEDIAN is selected.
- For 'resource_type', the most FREQUENT value is selected.
- For 'primary_focus_subject', the most FREQUENT value is selected.
- For 'primary_focus_area', the most FREQUENT value is selected.
- For 'grade_level', the most FREQUENT value is selected.
    >>> SUCCESS!

# For the following variables, dummy variables have been created.
    >>>['school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'eligible_double_your_impact_match']
    >>> SUCCESS!

# Attempting to DROP ['projectid', 'date_posted', 'datefullyfunded']...
    >>> SUCCESS!

#########################################################


#########################################################

# CREATING train/test sets with:
        - TRAIN SET: 2012-01-01 00:00:00 - 2012-11-01 00:00:00,
        - TEST SET: 2013-01-01 00:00:00 - 2013-06-30 00:00:00

# Discretizing 'teacher_prefix'...
    >>> SUCCESS!

# Discretizing 'school_state'...
    >>> SUCCESS!

# Attempting to IMPUTE the missing data...

- For 'school_metro', the most FREQUENT value is selected.
- For 'students_reached', the MEDIAN is selected.
- For 'resource_type', the most FREQUENT value is selected.
- For 'primary_focus_subject', the most FREQUENT value is selected.
- For 'primary_focus_area', the most FREQUENT value is selected.
- For 'grade_level', the most FREQUENT value is selected.
    >>> SUCCESS!

# For the following variables, dummy variables have been created.
    >>>['school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'eligible_double_your_impact_match']
    >>> SUCCESS!

# Attempting to DROP ['projectid', 'date_posted', 'datefullyfunded']...
    >>> SUCCESS!

#########################################################


#########################################################

# CREATING train/test sets with:
        - TRAIN SET: 2012-01-01 00:00:00 - 2013-05-01 00:00:00,
        - TEST SET: 2013-07-01 00:00:00 - 2013-12-31 00:00:00

# Discretizing 'teacher_prefix'...
    >>> SUCCESS!

# Discretizing 'school_state'...
    >>> SUCCESS!

# Attempting to IMPUTE the missing data...

- For 'school_metro', the most FREQUENT value is selected.
- For 'students_reached', the MEDIAN is selected.
- For 'resource_type', the most FREQUENT value is selected.
- For 'primary_focus_subject', the most FREQUENT value is selected.
- For 'primary_focus_area', the most FREQUENT value is selected.
- For 'grade_level', the most FREQUENT value is selected.
    >>> SUCCESS!

# For the following variables, dummy variables have been created.
    >>>['school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'eligible_double_your_impact_match']
    >>> SUCCESS!

# Attempting to DROP ['projectid', 'date_posted', 'datefullyfunded']...
    >>> SUCCESS!

#########################################################


# A Precision Recall curve has been saved as ./images/2012-07-01_0_prc.png.

# The evaluation has been saved as ./evaluations/2012-07-01_evaluations.csv.

# The best model for 2012-07-01 set has been selected.


# A Precision Recall curve has been saved as ./images/2013-01-01_0_prc.png.

# The evaluation has been saved as ./evaluations/2013-01-01_evaluations.csv.

# The best model for 2013-01-01 set has been selected.


# A Precision Recall curve has been saved as ./images/2013-07-01_0_prc.png.

# The evaluation has been saved as ./evaluations/2013-07-01_evaluations.csv.

# The best model for 2013-07-01 set has been selected.

[[LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=10, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], [LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=10, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)], [LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=10, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)]]

Job completed
