{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix\n",
    "from run import main\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Deleted the existing log file.\n",
      "\n",
      "# LOADING the data...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Converting the data into preconfigured dtypes...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "#########################################################\n",
      "\n",
      "SUMMARY for the loaded dataset\n",
      "\n",
      "The total number of rows is 124976\n",
      "\n",
      "The total number of rows is 25\n",
      "\n",
      "Descriptive Statistics:\n",
      "\n",
      "       school_ncesid  school_latitude  school_longitude  \\\n",
      "count  1.157430e+05   124976.000000    124976.000000      \n",
      "mean   2.448448e+11   36.827284       -95.859299          \n",
      "std    1.644728e+11   4.963669         18.392876          \n",
      "min    1.000050e+10   18.249140       -171.690554         \n",
      "25%    6.344101e+10   33.872504       -117.806418         \n",
      "50%    2.200870e+11   36.617410       -90.101563          \n",
      "75%    3.704880e+11   40.676156       -80.713740          \n",
      "max    6.100010e+11   65.672562       -66.628036          \n",
      "\n",
      "       total_price_including_optional_support  students_reached  \n",
      "count  124976.000000                           124917.000000     \n",
      "mean   654.011811                              95.445760         \n",
      "std    1098.015854                             163.481912        \n",
      "min    92.000000                               1.000000          \n",
      "25%    345.810000                              23.000000         \n",
      "50%    510.500000                              30.000000         \n",
      "75%    752.960000                              100.000000        \n",
      "max    164382.840000                           12143.000000      \n",
      "\n",
      "\n",
      "#########################################################\n",
      "\n",
      "\n",
      "# Attempting to SELECT the following features:\n",
      "    ['school_latitude', 'school_longitude', 'school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'total_price_including_optional_support', 'students_reached', 'eligible_double_your_impact_match', 'date_posted', 'datefullyfunded']...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to GENERATE a label called 'fullyfunded_within_60days' based on ['date_posted', 'datefullyfunded']...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to SPLIT the data temporally...\n",
      "# with each test set starting on the following dates:\n",
      "['2012-07-01', '2013-01-01', '2013-07-01']\n",
      "\n",
      "\n",
      "#########################################################\n",
      "\n",
      "# CREATING train/test sets with:\n",
      "        - TRAIN SET: 2012-01-01 00:00:00 - 2012-05-01 00:00:00,\n",
      "        - TEST SET: 2012-07-01 00:00:00 - 2012-12-31 00:00:00\n",
      "\n",
      "# Discretizing 'teacher_prefix'...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Discretizing 'school_state'...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to IMPUTE the missing data...\n",
      "\n",
      "- For 'school_metro', the most FREQUENT value is selected.\n",
      "- For 'students_reached', the MEDIAN is selected.\n",
      "- For 'resource_type', the most FREQUENT value is selected.\n",
      "- For 'primary_focus_subject', the most FREQUENT value is selected.\n",
      "- For 'primary_focus_area', the most FREQUENT value is selected.\n",
      "- For 'grade_level', the most FREQUENT value is selected.\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# For the following variables, dummy variables have been created.\n",
      "    >>>['school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'eligible_double_your_impact_match']\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to DROP ['projectid', 'date_posted', 'datefullyfunded']...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "#########################################################\n",
      "\n",
      "\n",
      "#########################################################\n",
      "\n",
      "# CREATING train/test sets with:\n",
      "        - TRAIN SET: 2012-01-01 00:00:00 - 2012-11-01 00:00:00,\n",
      "        - TEST SET: 2013-01-01 00:00:00 - 2013-06-30 00:00:00\n",
      "\n",
      "# Discretizing 'teacher_prefix'...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Discretizing 'school_state'...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to IMPUTE the missing data...\n",
      "\n",
      "- For 'school_metro', the most FREQUENT value is selected.\n",
      "- For 'students_reached', the MEDIAN is selected.\n",
      "- For 'resource_type', the most FREQUENT value is selected.\n",
      "- For 'primary_focus_subject', the most FREQUENT value is selected.\n",
      "- For 'primary_focus_area', the most FREQUENT value is selected.\n",
      "- For 'grade_level', the most FREQUENT value is selected.\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# For the following variables, dummy variables have been created.\n",
      "    >>>['school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'eligible_double_your_impact_match']\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to DROP ['projectid', 'date_posted', 'datefullyfunded']...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "#########################################################\n",
      "\n",
      "\n",
      "#########################################################\n",
      "\n",
      "# CREATING train/test sets with:\n",
      "        - TRAIN SET: 2012-01-01 00:00:00 - 2013-05-01 00:00:00,\n",
      "        - TEST SET: 2013-07-01 00:00:00 - 2013-12-31 00:00:00\n",
      "\n",
      "# Discretizing 'teacher_prefix'...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Discretizing 'school_state'...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to IMPUTE the missing data...\n",
      "\n",
      "- For 'school_metro', the most FREQUENT value is selected.\n",
      "- For 'students_reached', the MEDIAN is selected.\n",
      "- For 'resource_type', the most FREQUENT value is selected.\n",
      "- For 'primary_focus_subject', the most FREQUENT value is selected.\n",
      "- For 'primary_focus_area', the most FREQUENT value is selected.\n",
      "- For 'grade_level', the most FREQUENT value is selected.\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# For the following variables, dummy variables have been created.\n",
      "    >>>['school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'eligible_double_your_impact_match']\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to DROP ['projectid', 'date_posted', 'datefullyfunded']...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "#########################################################\n",
      "\n",
      "\n",
      "# The data for 2012-07-01 is saved.\n",
      "\n",
      "# The data for 2013-01-01 is saved.\n",
      "\n",
      "# The data for 2013-07-01 is saved.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'precision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-04d827ca6479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemporal_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/capp-machine-learning/DonorsChoose-machine-learning/run.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(log)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mlog_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOGGER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n# The data for {} is saved.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./evaluations/evaluations.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mlog_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOGGER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/capp-machine-learning/DonorsChoose-machine-learning/model.py\u001b[0m in \u001b[0;36mfind_best_model\u001b[0;34m(split_set, grid, scale, save)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTUNING\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/donorsml/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   4717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4718\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4719\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/donorsml/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1704\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'precision'"
     ]
    }
   ],
   "source": [
    "best_models = main(log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = temporal_sets[2][1][0]\n",
    "test_df = temporal_sets[2][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temporal_sets[2][1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_df['date_posted'].min())\n",
    "#print(test_df['date_posted'].max())\n",
    "#print(train_df['date_posted'].min())\n",
    "#print(train_df['date_posted'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = test_df.reset_index()\n",
    "#test_df = test_df.drop(['projectid', 'date_posted', 'datefullyfunded'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ValueError: operands could not be broadcast together with shapes (44167,68) (67,) (44167,68)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
