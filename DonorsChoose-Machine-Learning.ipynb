{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix\n",
    "from run import main\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Deleted the existing log file.\n",
      "\n",
      "# LOADING the data...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Converting the data into preconfigured dtypes...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "#########################################################\n",
      "\n",
      "SUMMARY for the loaded dataset\n",
      "\n",
      "The total number of rows is 124976\n",
      "\n",
      "The total number of rows is 25\n",
      "\n",
      "Descriptive Statistics:\n",
      "\n",
      "       school_ncesid  school_latitude  school_longitude  \\\n",
      "count  1.157430e+05   124976.000000    124976.000000      \n",
      "mean   2.448448e+11   36.827284       -95.859299          \n",
      "std    1.644728e+11   4.963669         18.392876          \n",
      "min    1.000050e+10   18.249140       -171.690554         \n",
      "25%    6.344101e+10   33.872504       -117.806418         \n",
      "50%    2.200870e+11   36.617410       -90.101563          \n",
      "75%    3.704880e+11   40.676156       -80.713740          \n",
      "max    6.100010e+11   65.672562       -66.628036          \n",
      "\n",
      "       total_price_including_optional_support  students_reached  \n",
      "count  124976.000000                           124917.000000     \n",
      "mean   654.011811                              95.445760         \n",
      "std    1098.015854                             163.481912        \n",
      "min    92.000000                               1.000000          \n",
      "25%    345.810000                              23.000000         \n",
      "50%    510.500000                              30.000000         \n",
      "75%    752.960000                              100.000000        \n",
      "max    164382.840000                           12143.000000      \n",
      "\n",
      "\n",
      "#########################################################\n",
      "\n",
      "\n",
      "# Attempting to SELECT the following features:\n",
      "    ['school_latitude', 'school_longitude', 'school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'total_price_including_optional_support', 'students_reached', 'eligible_double_your_impact_match', 'date_posted', 'datefullyfunded']...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to GENERATE a label called 'fullyfunded_within_60days' based on ['date_posted', 'datefullyfunded']...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to SPLIT the data temporally...\n",
      "# with each test set starting on the following dates:\n",
      "['2012-07-01', '2013-01-01', '2013-07-01']\n",
      "\n",
      "\n",
      "#########################################################\n",
      "\n",
      "# CREATING train/test sets with:\n",
      "        - TRAIN SET: 2012-01-01 00:00:00 - 2012-05-01 00:00:00,\n",
      "        - TEST SET: 2012-07-01 00:00:00 - 2012-12-31 00:00:00\n",
      "\n",
      "# Discretizing 'teacher_prefix'...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Discretizing 'school_state'...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to IMPUTE the missing data...\n",
      "\n",
      "- For 'school_metro', the most FREQUENT value is selected.\n",
      "- For 'students_reached', the MEDIAN is selected.\n",
      "- For 'resource_type', the most FREQUENT value is selected.\n",
      "- For 'primary_focus_subject', the most FREQUENT value is selected.\n",
      "- For 'primary_focus_area', the most FREQUENT value is selected.\n",
      "- For 'grade_level', the most FREQUENT value is selected.\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# For the following variables, dummy variables have been created.\n",
      "    >>>['school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'eligible_double_your_impact_match']\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to DROP ['projectid', 'date_posted', 'datefullyfunded']...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "#########################################################\n",
      "\n",
      "\n",
      "#########################################################\n",
      "\n",
      "# CREATING train/test sets with:\n",
      "        - TRAIN SET: 2012-01-01 00:00:00 - 2012-11-01 00:00:00,\n",
      "        - TEST SET: 2013-01-01 00:00:00 - 2013-06-30 00:00:00\n",
      "\n",
      "# Discretizing 'teacher_prefix'...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Discretizing 'school_state'...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to IMPUTE the missing data...\n",
      "\n",
      "- For 'school_metro', the most FREQUENT value is selected.\n",
      "- For 'students_reached', the MEDIAN is selected.\n",
      "- For 'resource_type', the most FREQUENT value is selected.\n",
      "- For 'primary_focus_subject', the most FREQUENT value is selected.\n",
      "- For 'primary_focus_area', the most FREQUENT value is selected.\n",
      "- For 'grade_level', the most FREQUENT value is selected.\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# For the following variables, dummy variables have been created.\n",
      "    >>>['school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'eligible_double_your_impact_match']\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to DROP ['projectid', 'date_posted', 'datefullyfunded']...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "#########################################################\n",
      "\n",
      "\n",
      "#########################################################\n",
      "\n",
      "# CREATING train/test sets with:\n",
      "        - TRAIN SET: 2012-01-01 00:00:00 - 2013-05-01 00:00:00,\n",
      "        - TEST SET: 2013-07-01 00:00:00 - 2013-12-31 00:00:00\n",
      "\n",
      "# Discretizing 'teacher_prefix'...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Discretizing 'school_state'...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to IMPUTE the missing data...\n",
      "\n",
      "- For 'school_metro', the most FREQUENT value is selected.\n",
      "- For 'students_reached', the MEDIAN is selected.\n",
      "- For 'resource_type', the most FREQUENT value is selected.\n",
      "- For 'primary_focus_subject', the most FREQUENT value is selected.\n",
      "- For 'primary_focus_area', the most FREQUENT value is selected.\n",
      "- For 'grade_level', the most FREQUENT value is selected.\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# For the following variables, dummy variables have been created.\n",
      "    >>>['school_state', 'school_metro', 'school_charter', 'school_magnet', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'eligible_double_your_impact_match']\n",
      "    >>> SUCCESS!\n",
      "\n",
      "# Attempting to DROP ['projectid', 'date_posted', 'datefullyfunded']...\n",
      "    >>> SUCCESS!\n",
      "\n",
      "#########################################################\n",
      "\n",
      "\n",
      "# The evaluation has been saved as ./evaluations/2012-07-01_evaluations.csv.\n",
      "\n",
      "# The best model for for 2012-07-01 set has been selected.\n"
     ]
    }
   ],
   "source": [
    "best_models = main(log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = temporal_sets[2][1][0]\n",
    "test_df = temporal_sets[2][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temporal_sets[2][1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_df['date_posted'].min())\n",
    "#print(test_df['date_posted'].max())\n",
    "#print(train_df['date_posted'].min())\n",
    "#print(train_df['date_posted'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = test_df.reset_index()\n",
    "#test_df = test_df.drop(['projectid', 'date_posted', 'datefullyfunded'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ValueError: operands could not be broadcast together with shapes (44167,68) (67,) (44167,68)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
